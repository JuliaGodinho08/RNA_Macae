{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PreProcessamento.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "NcaVV65Sri7E",
        "UD4dbdN1gh01"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cc-VQd9hNS4p"
      },
      "source": [
        "#**Funções de pré-processamento**\n",
        "Nome: Julia da Silva Godinho (juliagodinho08@gmail.com)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Nesse notebook são definidas as funções:\n",
        "\n",
        "* `preprocessamento`  pre-processamento dos dados\n",
        "* `regressao`  preenchimento de falhas\n",
        "* `KNN`  preenchimento de falhas\n",
        "* `criando_dados_modelo` para crianção do df com variveis do modelo\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsvitfBPAfOX"
      },
      "source": [
        "## Abrindo os arquivos \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49bp3cgiTybm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24b03d02-45c2-4656-e46c-76b337990b69"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import statsmodels.api as sm\n",
        "import numpy as np\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "#!pip install icecream\n",
        "#sfrom icecream import ic\n",
        "\n",
        "#Abrindo o arquivo \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting icecream\n",
            "  Downloading https://files.pythonhosted.org/packages/31/cc/5454531fe9ae123720b496fdea806e282843d6e75e5718a5e8b1d8e5c47f/icecream-2.1.0-py2.py3-none-any.whl\n",
            "Collecting asttokens>=2.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/62/e9/247023d33dc110117b831cbfe47bb553e10d0edf92297ace745256402d42/asttokens-2.0.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pygments>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from icecream) (2.6.1)\n",
            "Collecting executing>=0.3.1\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/3d/2c2cf37d6194fa93c35e7ba6ab5aaa841a9b1b788fc322b01e53e0602049/executing-0.5.4-py3-none-any.whl\n",
            "Collecting colorama>=0.3.9\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from asttokens>=2.0.1->icecream) (1.15.0)\n",
            "Installing collected packages: asttokens, executing, colorama, icecream\n",
            "Successfully installed asttokens-2.0.4 colorama-0.4.4 executing-0.5.4 icecream-2.1.0\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJ8Lr9JYUQMp"
      },
      "source": [
        "galdiArquivo = '/content/drive/My Drive/IC - Aprendizado de Máquina/Arquivos CSV/chuvas_C_02242004.csv'\n",
        "oratArquivo = '/content/drive/My Drive/IC - Aprendizado de Máquina/Arquivos CSV/Pluvio 2241004 Fazenda Oratorio.csv'\n",
        "pillerArquivo = \"/content/drive/MyDrive/IC - Aprendizado de Máquina/Arquivos CSV/chuvas_C_02242003.csv\"\n",
        "PillerFluArquivo = '/content/drive/MyDrive/IC - Aprendizado de Máquina/Arquivos CSV/vazoes_C_59135000.csv'\n",
        "\n",
        "data_galdi = pd.read_csv(galdiArquivo,index_col=False,skiprows=12,encoding='latin-1',sep=';')\n",
        "data_orat = pd.read_csv(oratArquivo,index_col=False,skiprows=12,encoding='latin-1',sep=';')\n",
        "data_piller = pd.read_csv(pillerArquivo,index_col=False,skiprows=12,encoding='latin-1',sep=';')\n",
        "data_flu_piller = pd.read_csv(PillerFluArquivo,index_col=False,skiprows=12,encoding='latin-1',sep=';')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FU_bRvVWN-uz"
      },
      "source": [
        "##**Função `preprocessamento` - Organização dos Dados**\n",
        "\n",
        "**Parametros**:\n",
        "* `df` dataframe \n",
        "* `colunas_dados` as colunas de interesse que serão mantidas após os tratamentos\n",
        "* `coluna_index` o nome da coluna que possui as datas\n",
        "* `nome_estacao` o nome da estação\n",
        "\n",
        "Essa função retorna um dataframe com dados mensais:\n",
        "\n",
        "* filtadro com os colunas de interesse\n",
        "* com index em datetime\n",
        "* com uma observação por mês\n",
        "* dados convertidos para float \n",
        "* sem datas duplicadas\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CByC-_zJLxkD"
      },
      "source": [
        "def preprocessamento (df, colunas_dados, coluna_index, nome_estacao, \n",
        "                      dados = \"consistidos\", freq = \"mensal\", \n",
        "                      inicio = None, fim = None,\n",
        "                      eto = False):\n",
        "  \n",
        "  \"\"\"Retorna o dataframe com index ordenado, em formato datetime e com os dados em float. \n",
        "    Para observações diárias, retorna com uma observação por linha. \n",
        "\n",
        "------\n",
        "  Parâmetros\n",
        "   - `df`: dataframe com os dados brutos\n",
        "   - `colunas_dados`: conjunto de colunas que serão mantidas no df\n",
        "   - `coluna_index`: nome da coluna que vivará o index\n",
        "   - `nome_estacao`: nome da estacao \n",
        "   - `dados`: escolher entre manter os dados 'brutos' os ou dados 'consistidos' \n",
        "   - `freq`: escolher entre duas frequências 'diaria' ou 'mensal'\n",
        "   - `inicio`: dada de inicio da série temporal (Opcional)\n",
        "   - `fim`: data final da série temporal (Opcional)\n",
        "   - `eto`: True se o dataframe for para calculo da ETo\n",
        "   \"\"\"\n",
        "\n",
        "  df2 = df.loc[:]\n",
        "\n",
        "  # 1 - RETIRADA DE DADOS DUPLICADOS\n",
        "  # Mantem a ultima ocorrência que representam as observações consistidas\n",
        "  if dados == \"brutos\": #os dados brutos são as primeira ocorrências\n",
        "    df2 = df2.drop_duplicates([coluna_index], keep='first')\n",
        "  else: #os dados consistidos são as segundas ocorrências\n",
        "    df2 = df2.drop_duplicates([coluna_index], keep='last')\n",
        "\n",
        "  # 2 - ALTERAÇÃO E ORDENAÇÃO DO INDEX\n",
        "  # Ordenação crescente\n",
        "  df2[coluna_index] = pd.to_datetime(df2[coluna_index],format='%d/%m/%Y')\n",
        "  df2 = df2.set_index(coluna_index)\n",
        "  df2 = df2.sort_index(axis=0,ascending=True)\n",
        "  \n",
        "  # 3 - CONVERSÃO DOS DADOS PARA FLOAT\n",
        "  for coluna in colunas_dados:\n",
        "    df2[coluna] = df2[coluna].apply(lambda x: str(x).replace(',','.'))\n",
        "    df2[coluna] = df2[coluna].astype(float)\n",
        "\n",
        "  # 4 - GARANTINDO A FREQUENCIA DOS DADOS\n",
        "\n",
        "  # 4.1 ESTAÇÕES METEREOLOGICAS - EVAPOTRANSPIRAÇAO\n",
        "  if eto:  \n",
        "\n",
        "    df3 = pd.DataFrame(columns = colunas_dados)\n",
        "\n",
        "    if freq == 'diaria': f = 'D'\n",
        "    else: f = 'M'\n",
        "\n",
        "    for coluna in colunas_dados:\n",
        "      if coluna == 'PRECIPITACAO TOTAL, DIARIO (AUT)(mm)':\n",
        "        df3[coluna] = df2[coluna].resample(f).sum()\n",
        "        #print('oi')\n",
        "      else: \n",
        "        #print('Falso')\n",
        "        df3[coluna] = df2[coluna].resample(f).mean()\n",
        "\n",
        "  # 4.2 ESTAÇOES FLUVIOMETRICAS E PLUVIOMETRICAS\n",
        "  else: \n",
        "    \n",
        "    # Caso a data não exista, será criada uma nova linha com dados nulos \n",
        "    df_mensal = df2.resample('M').mean()\n",
        "    \n",
        "    # 4.2.1 DADOS DIARIOS - TRANSFORMANDO LINHA EM COLUNA\n",
        "    if freq == \"diaria\":\n",
        "      # Garantindo que tenha uma linha por dia\n",
        "      df_diario = df2.resample('D').mean()\n",
        "\n",
        "      # Criando um dataframe com somente uma coluna para dados diários\n",
        "      indices = df_diario.index\n",
        "      df3 = pd.DataFrame(data = None, index = indices, columns = ['Dados'])\n",
        "\n",
        "      for dados_mensais in df_mensal.index: \n",
        "        data_obs = dados_mensais.strftime(\"%Y-%m-%d\")\n",
        "        num_dias = dados_mensais.daysinmonth\n",
        "    \n",
        "        for dados_diarios, dia in zip(colunas_dados, range(1,num_dias+1)):\n",
        "          # Acessando os valores diários\n",
        "          value = df_mensal.loc[data_obs,dados_diarios]\n",
        "\n",
        "          # Armazenando o valor na data correspodente\n",
        "          data = dados_mensais.replace(day = dia)\n",
        "          df3.loc[data,'Dados'] = value\n",
        "\n",
        "    # 4.2.2. DADOS MENSAIS\n",
        "    else:  \n",
        "      df3 = df_mensal[colunas_dados]\n",
        "  \n",
        "  # Selecionando o intervalo temporal dos dados \n",
        "  if inicio != None and fim != None:\n",
        "    df3 = df3[inicio:fim]\n",
        "  \n",
        "  # 5 - RETORNA A BASE HISTORICA DA ESTACAO E QUANTIDADE DE FALHAS\n",
        "  #falhas = df2[colunas_dados].isnull().sum().sum()\n",
        "  observacoes = df3.shape[0]\n",
        "  data_inicio = df3.index[0].strftime(\"%d-%m-%Y\") \n",
        "  data_fim = df3.index[observacoes-1].strftime(\"%d-%m-%Y\")\n",
        "  falhas = df3.isnull().sum().sum()\n",
        "  print('%s | Observações: %i | Freq: %s | Período: %s a %s | Falhas: %i' %(nome_estacao,\n",
        "                                                              observacoes,\n",
        "                                                              str(freq),\n",
        "                                                              data_inicio,\n",
        "                                                              data_fim,\n",
        "                                                              falhas))\n",
        "\n",
        "  return (df3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcaVV65Sri7E"
      },
      "source": [
        "### Teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9UAHwpmeYR0"
      },
      "source": [
        "# Macae_Arquivo = '/content/drive/My Drive/IC - Aprendizado de Máquina/Climático/dados_A608_D_2006-09-21_2020-04-01.csv'\n",
        "# df_macae = pd.read_csv(Macae_Arquivo,index_col=False,skiprows=10,encoding='latin-1',sep=';') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGe1PKAneY9m"
      },
      "source": [
        "# # As colunas de interesse \n",
        "# colunas_macae = ['PRECIPITACAO TOTAL, DIARIO (AUT)(mm)','TEMPERATURA MAXIMA, DIARIA (AUT)(Â°C)',\n",
        "#            'TEMPERATURA MEDIA, DIARIA (AUT)(Â°C)','TEMPERATURA MINIMA, DIARIA (AUT)(Â°C)',\n",
        "#            'UMIDADE RELATIVA DO AR, MEDIA DIARIA (AUT)(%)','VENTO, VELOCIDADE MEDIA DIARIA (AUT)(m/s)']\n",
        "\n",
        "# # Mudando o formato da datas de medição\n",
        "# # para ficarem compatíveis com as previstas na função de preprocessamento\n",
        "# df_macae['Data Medicao'] = pd.to_datetime(df_macae['Data Medicao'],format='%Y/%m/%d')\n",
        "\n",
        "# # Fazendo o preprocessamento dos dados\n",
        "# data_macae = preprocessamento(df_macae,colunas_macae,'Data Medicao',\n",
        "#                               'Automática Macae', inicio = '10-2006',\n",
        "#                               fim = '03-2020', eto = True)\n",
        "\n",
        "# data_macae"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdlytKWC7sBg",
        "outputId": "8aa04b16-3f4e-4808-fe01-f26574f4ccf7"
      },
      "source": [
        "# col = data_piller.columns[13:44] #para dados diários\n",
        "# col2 = ['Total','Maxima','NumDiasDeChuva'] #para dados mensais\n",
        "# col_flu = data_flu_piller.columns[16:47]\n",
        "\n",
        "# piller_diario = preprocessamento(data_piller, colunas_dados = col,\n",
        "#                              coluna_index = \"Data\",\n",
        "#                              nome_estacao = \"Piller\", freq = 'diaria', \n",
        "#                              inicio = '1997', fim = '1998')\n",
        "\n",
        "# piller_flu_diario = preprocessamento(data_flu_piller, colunas_dados = col_flu,\n",
        "#                              coluna_index = \"Data\",\n",
        "#                              nome_estacao = \"Piller\", freq = 'diaria', \n",
        "#                              inicio = '1997', fim = '1998')\n",
        "\n",
        "\n",
        "# piller_mensal = preprocessamento(data_piller, col2, coluna_index = \"Data\",\n",
        "#                                 nome_estacao = \"Piller\")\n",
        "\n",
        "# galdi_diario = preprocessamento(data_galdi, col, \"Data\", \"Galdinópolis\",\n",
        "#                                 freq = 'diaria', inicio = '1997', fim = '1998')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A estação Piller tem 730 observações com frequencia diaria de 01-01-1997 até 31-12-1998\n",
            "A estação Piller tem 730 observações com frequencia diaria de 01-01-1997 até 31-12-1998\n",
            "A estação Piller tem 837 observações com frequencia mensal de 31-08-1950 até 30-04-2020\n",
            "A estação Galdinópolis tem 730 observações com frequencia diaria de 01-01-1997 até 31-12-1998\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Klfee4VXe6c"
      },
      "source": [
        "##**Função `regressao` - Preenchimento de Falhas**\n",
        "\n",
        "**Parametros**:\n",
        "* `df_y` dataframe com as variaveis alvo \n",
        "* `df_x` dataframe com variaveis preditoras\n",
        "* `colunas_y` colunas com as falhas \n",
        "* `colunas_x` colunas da variavel preditora\n",
        "\n",
        "A função retorna o dataframe `df_y` com novas colunas em que as falhas foram preenchidas. \n",
        "\n",
        "Antes de serem usadas nos modelos, todas as colunas são interpoladas para terem suas falhas preenchidas. \n",
        "\n",
        "A função de regressão linear está com o parâmetro *Normalize = True*\n",
        "\n",
        "**Tutoriais usados:** [Kaggle](https://www.kaggle.com/shashankasubrahmanya/missing-data-imputation-using-regression), [Medium](https://medium.com/data-hackers/implementando-regress%C3%A3o-linear-simples-em-python-91df53b920a8)\n",
        "\n",
        "**Documentação SciKit Learn** [link](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html?highlight=linearregression#sklearn.linear_model.LinearRegression)\n",
        "\n",
        "**Pendências:**\n",
        "* Calcular a eficiencia da regressão \n",
        "* Preencher as falhas por outros métodos e comparar\n",
        "* Estudo de correlação para saber qual o melhor posto paa usar de preditor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnxDBbRKbqOM"
      },
      "source": [
        "def regressao (df_y, df_x, colunas_y, colunas_x):\n",
        "\n",
        "  '''A função retorna o dataframe com novas colunas com as falhas preenchidas por regressão\n",
        "  \\nOBS: Usar outros postos como variável preditora  \n",
        "  \\nOBS2: Realiza interpolação nas colunas antes do modelo de regressão\n",
        "\n",
        "  ----\n",
        "  Parâmetros:\n",
        "  df_y: o dataframe que terá suas falhas preenchidas (precessora)\n",
        "  df_x: o dataframe que servirá de variável preditora \n",
        "  colunas_y: colunas que possuem falhas\n",
        "  colunas_x: colunas que serão usadas como preditora\n",
        "  \n",
        "  '''\n",
        "  \n",
        "  for coluna in colunas_y:\n",
        "\n",
        "    ### 1 - IMPLEMENTANDO O MODELO\n",
        "\n",
        "    # Criando novas colunas que terao as falhas preenchidas  \n",
        "    df_y[coluna+'_R']=df_y[coluna]\n",
        "\n",
        "    # Criando um dataframe com as variaveis do modelo\n",
        "    df = pd.DataFrame(index=df_y.index)\n",
        "    # variável alvo - interpolando as falhas\n",
        "    df['y'] = df_y[coluna].interpolate() \n",
        "    # variável preditora - interpolando as falhas\n",
        "    df[colunas_x] = df_x[colunas_x].interpolate()\n",
        "    \n",
        "    # Criando o modelo\n",
        "    model = LinearRegression(normalize=True)\n",
        "    # Definindo as variaveis \n",
        "    X = df[colunas_x]\n",
        "    y = df['y']\n",
        "    # Treinando o modelo\n",
        "    model.fit(X,y)\n",
        "\n",
        "    # Fazendo a previsão \n",
        "    predict = model.predict(X)\n",
        "    df[coluna+'_R'] = predict\n",
        "    # Preenchendo as falhas com as previsões do modelo\n",
        "    df_y.loc[df_y[coluna].isnull(), coluna + '_R'] =  model.predict(X)[df_y[coluna].isnull()]\n",
        "\n",
        "    # 2 - AVALIANDO O MODELO\n",
        "    #print(model.score(X,y))\n",
        "\n",
        "  return (df_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Q137KJepTsA"
      },
      "source": [
        "def regressao2 (df_y, df_x, colunas_y, colunas_x):\n",
        "\n",
        "  '''A função retorna o dataframe com novas colunas com as falhas preenchidas por regressão\n",
        "  \\nOBS: Usar outros postos como variável preditora  \n",
        "  \\nOBS2: Realiza preenchimento das falhas com `fillna()` antes do modelo de regressão\n",
        "\n",
        "  ----\n",
        "  Parâmetros:\n",
        "\n",
        "  `df_y`: o dataframe que terá suas falhas preenchidas (precessora)\n",
        "  `df_x`: o dataframe que servirá de variável preditora \n",
        "  `colunas_y`: colunas que possuem falhas\n",
        "  `colunas_x`: colunas que serão usadas como preditora\n",
        "  \n",
        "  '''\n",
        "##### CONJUNTO DE DADOS\n",
        "  df = pd.DataFrame(index=df_y.index)\n",
        "\n",
        "  Y = df_y[col_y]\n",
        "\n",
        "  # Preenchimento da estação preditora com KNN\n",
        "  X = df_x[col_X]\n",
        "  imputer = KNNImputer()\n",
        "  X = imputer.fit_transform(X)\n",
        "\n",
        "  # Divisão dos dados \n",
        "  X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=42)\n",
        "\n",
        "##### IMPLEMENTANDO O MODELO DE REGRESSAO\n",
        "      \n",
        "  model = LinearRegression(normalize=True)\n",
        "\n",
        "  # Treinando o modelo\n",
        "  model.fit(X_train,y_train)\n",
        "\n",
        "  # Fazendo a previsão \n",
        "  y_pred = model.predict(X_test)\n",
        "  df[coluna+'_R'] = y_pred\n",
        "\n",
        "##### ARMAZENANDO OS RESULTADOS\n",
        "\n",
        "  # Criando novas colunas que terao as falhas preenchidas  \n",
        "  df_y[coluna+'_R']=df_y[coluna]\n",
        "\n",
        "  # Preenchendo as falhas com as previsões do modelo\n",
        "  df_y.loc[df_y[coluna].isnull(), coluna + '_R'] =  model.predict(X)[df_y[coluna].isnull()]\n",
        "\n",
        "##### AVALIANDO O MODELO\n",
        "  print(model.score(X_test,y_pred))\n",
        "\n",
        "  return (df_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVnHfKxW7U0F"
      },
      "source": [
        "Tutorial do Medium \n",
        "[link](https://medium.com/@Cambridge_Spark/tutorial-introduction-to-missing-data-imputation-4912b51c34eb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJMQtE-O7Ue5"
      },
      "source": [
        "def regressao3 (df, col_X, col_y):\n",
        "\n",
        "  '''Função para preenchimento de falhas. \n",
        "  O conjunto de treino consiste no df sem as falhas.\n",
        "  Usa o KNN inputer para o conjunto de teste.\n",
        "\n",
        "  Parâmetros:\n",
        "  - df: dataframe com as falhas \n",
        "  - col_x: nome das colunas preditoras\n",
        "  - col_y: nome das colunas que terão suas falhas preenchidas\n",
        "\n",
        "  Atualizado\n",
        "  '''\n",
        "\n",
        "  ### DIVISAO DO CONJUNTO DE DADOS\n",
        "\n",
        "  # Conjutno de Treinamento - Criar um subset sem as falhas \n",
        "  df_2 = pd.DataFrame(df)\n",
        "  df_2 = df_2.dropna(subset = [col_y])\n",
        "  df_2 = df_2.dropna(subset = col_X)\n",
        "  \n",
        "  X_train = df_2[col_X]\n",
        "  y_train = df_2[col_y]\n",
        "\n",
        "  # Conjunto de Teste - dataset completo com falhas preenchidas por KNN\n",
        "  X_test = pd.DataFrame(df[col_X])\n",
        "  imputer = KNNImputer()\n",
        "  X_test = imputer.fit_transform(X_test)\n",
        "\n",
        "  #X_test = X_test[col_X][y_falhas]\n",
        "\n",
        "  # Criar subset somente com as falhas \n",
        "  y_falhas = df[col_y].isnull()\n",
        " \n",
        "  ###IMPLEMENTANDO O MODELO\n",
        "\n",
        "  # Criando o modelo\n",
        "  model = LinearRegression(normalize=True)\n",
        "\n",
        "  # Treinando o modelo\n",
        "  model.fit(X_train,y_train)\n",
        "\n",
        "  # Fazendo a previsão com dados de teste\n",
        "  predict = model.predict(X_test)\n",
        "  y_falhas['Previsão'] = predict\n",
        "\n",
        "  ###ARMAZENANDO OS RESULTADOS\n",
        "\n",
        "  # Criando novas colunas que terao as falhas preenchidas  \n",
        "  df[str(col_y)+'_R']=df[col_y]\n",
        "\n",
        "  # Preenchendo as falhas com as previsões do modelo\n",
        "  df.loc[df[col_y].isnull(), str(col_y) + '_R'] =   predict[df[col_y].isnull()]\n",
        "\n",
        "  #AVALIANDO O MODELO\n",
        "  #model.score(X_train,y_train)\n",
        "\n",
        "  return (df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UD4dbdN1gh01"
      },
      "source": [
        "### **Teste**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "SsvSWqw51JBu",
        "outputId": "a0b5d38c-6af3-4fbf-c02b-1eaae1c7fdea"
      },
      "source": [
        "# piller_mensal_R = regressao3(piller_mensal, ['Maxima','NumDiasDeChuva'], 'Total') \n",
        "# piller_mensal_R['08-2019':'03-2020']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Total</th>\n",
              "      <th>Maxima</th>\n",
              "      <th>NumDiasDeChuva</th>\n",
              "      <th>Total_R</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Data</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2019-08-31</th>\n",
              "      <td>52.2</td>\n",
              "      <td>7.4</td>\n",
              "      <td>13.0</td>\n",
              "      <td>52.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-09-30</th>\n",
              "      <td>93.8</td>\n",
              "      <td>18.4</td>\n",
              "      <td>13.0</td>\n",
              "      <td>93.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-31</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>186.278448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-11-30</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>241.629228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-12-31</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>296.980008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-01-31</th>\n",
              "      <td>301.1</td>\n",
              "      <td>32.8</td>\n",
              "      <td>27.0</td>\n",
              "      <td>301.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-02-29</th>\n",
              "      <td>222.9</td>\n",
              "      <td>26.3</td>\n",
              "      <td>25.0</td>\n",
              "      <td>222.900000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-03-31</th>\n",
              "      <td>250.0</td>\n",
              "      <td>36.3</td>\n",
              "      <td>20.0</td>\n",
              "      <td>250.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Total  Maxima  NumDiasDeChuva     Total_R\n",
              "Data                                                 \n",
              "2019-08-31   52.2     7.4            13.0   52.200000\n",
              "2019-09-30   93.8    18.4            13.0   93.800000\n",
              "2019-10-31    NaN     NaN             NaN  186.278448\n",
              "2019-11-30    NaN     NaN             NaN  241.629228\n",
              "2019-12-31    NaN     NaN             NaN  296.980008\n",
              "2020-01-31  301.1    32.8            27.0  301.100000\n",
              "2020-02-29  222.9    26.3            25.0  222.900000\n",
              "2020-03-31  250.0    36.3            20.0  250.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spgcs42hDlAc"
      },
      "source": [
        "##**Função `KNN` - Preenchimento de Falhas**\n",
        "\n",
        "A função retorna o DataFrame com novas colunas onde as falhas foram preenchidas pelo método *k-Nearest Neighbors*. \n",
        "\n",
        "**Parâmetros:**\n",
        "* `df` DataFrame com as falhas\n",
        "* `colunas_falhas` colunas com falhas - deve ser mais de uma coluna (?)\n",
        "\n",
        "**Fonte:** [SciKit Learn](https://scikit-learn.org/stable/modules/impute.html#nearest-neighbors-imputation)\n",
        "\n",
        "**Pendências:**\n",
        "* avaliação de desempenho no modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4RVuxaODt2u"
      },
      "source": [
        "def KNN(df, colunas_falhas):\n",
        "\n",
        "  '''A função retorna o DataFrame com novas colunas com as falhas preenchidas \n",
        "  pela algortimo de k-Nearest Neighbors\n",
        "  '''\n",
        "\n",
        "  for coluna in colunas_falhas:\n",
        "\n",
        "    # Definindo o modelo\n",
        "    model = KNNImputer()\n",
        "    # Definindo a variável\n",
        "    X = df[colunas_falhas]\n",
        "    # Treinando e executando o modelo \n",
        "    previsao = model.fit_transform(X)\n",
        "\n",
        "    # Criando um DataFrame com os resultados\n",
        "    df_KNN=pd.DataFrame(data = previsao, index = df.index, columns = colunas_falhas )\n",
        "    \n",
        "    # Inserindo uma coluna com as falhas preenchidas\n",
        "    df[coluna+'_KNN'] = df_KNN[coluna]\n",
        "\n",
        "  return (df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdQSlvyOZbbs"
      },
      "source": [
        "##Função `criando_dados_modelo` - Criação das variáveis dos modelo [Não usada]\n",
        "\n",
        "Essa função retorna um dataframe com todas as variaveis que serão usadas no modelo de redes neurais, de acordo como especificações de entrada indicada no df `modelos_entradas`. \n",
        "\n",
        "A última coluna será a variável alvo, e as demais serão as variáveis preditoras\n",
        "\n",
        "\n",
        "**Parâmetros**:\n",
        "  - `modelos_entradas` dataframe que possui as opções de entrada que serão testadas\n",
        "  - `num_modelo` o número do modelo que será criado\n",
        "  - `df_pluvio` df e coluna que possui as dados pluviométricos médios\n",
        "  - `df_vazaomontante` df e coluna com as vazões médias da estação que será usada\n",
        "  como controle à montante\n",
        "  - `df_vazao` df e coluna com as vazões médias que será a variáveis y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77l07zd0ipyk"
      },
      "source": [
        "def criando_dados_modelo2(modelos_entradas,num_modelo,df_entradas):\n",
        "\n",
        "  '''Essa função retorna:\n",
        "  - data_modelo: df com todos as colunas \n",
        "  - colunas_x: df com caracteristicas\n",
        "  - colunas_y: df com variavel alvo\n",
        "\n",
        "  A última coluna será a variável alvo, e as demais serão as variáveis x\n",
        "\n",
        "  ----\n",
        "\n",
        "  Parâmetros:\n",
        "  - `modelos_entradas`: dataframe que possui as opções de entrada que serão testadas\n",
        "  - `num_modelo`: o número do modelo que será criado\n",
        "  - `df_entradas`: df contendo todas as caracteristicas disponiveis\n",
        "  Atualizado2\n",
        "  '''\n",
        "\n",
        "  defasagem = modelos_entradas['Def'][num_modelo]\n",
        "  data_modelo = pd.DataFrame()\n",
        "  colunas_x = []\n",
        "\n",
        "  # 1. CARACTERISTICAS\n",
        "\n",
        "  for column in df_entradas:\n",
        "    \n",
        "    # Caso a caracteristica esteja no modelo\n",
        "    if modelos_entradas.loc[num_modelo, column]:\n",
        "      # Adicionando os dados em defasagem\n",
        "      for i in range(1,defasagem+1):\n",
        "        coluna = str(column) + ' T-' +str(i)\n",
        "        data_modelo[coluna] = df_entradas[column].shift(-i)\n",
        "        colunas_x.append(coluna)\n",
        "     \n",
        "  # 2. VARIAVEL ALVO\n",
        "  data_modelo['Vazao_T'] = df_entradas['V_Galdi']\n",
        "\n",
        "  # Excluindo as instancias com falhas que surgem quando fazemos a defasagem\n",
        "  data_modelo.dropna(0,inplace=True)\n",
        "\n",
        "  # Retornando algumas informações do modelo\n",
        "  instancias, observacoes  = data_modelo.shape[0], data_modelo.size\n",
        "  inicio, fim = data_modelo.index[0], data_modelo.index[instancias-1]\n",
        "\n",
        "  modelos_entradas.loc[num_modelo,'Inicio'] = inicio\n",
        "  modelos_entradas.loc[num_modelo,'Fim'] = fim\n",
        "  modelos_entradas.loc[num_modelo,'Observacoes'] = observacoes\n",
        "\n",
        "  # Coeficiente de Correlação de Pearson \n",
        "  corr = data_modelo.corr().mean().mean()\n",
        "  modelos_entradas.loc[num_modelo,'Correlacao'] = corr\n",
        "\n",
        "  # Retornando as colunas X e Y\n",
        "  colunas_y = data_modelo['Vazao_T']\n",
        "  colunas_x = data_modelo[colunas_x]\n",
        "\n",
        "  print('O modelo %i possui %i observações, de %s a %s (%i meses).'%(num_modelo,\n",
        "                                                          observacoes,\n",
        "                                                          str(inicio),\n",
        "                                                          str(fim),\n",
        "                                                          instancias))\n",
        "  return (data_modelo,colunas_x,colunas_y)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}